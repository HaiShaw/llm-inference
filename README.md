## llm-inference

### LLM Inference benchmarking utils. for Nvidia and AMD DCGPUs

- Verified models: OPT-66B, LLaMa-65B and below
- DCGPUs: H100, A100, V100, MI300, MI250, MI100
- SW stack: HuggingFace, PyTorch
       WIP: DeepSpeed, FasterTransformer

